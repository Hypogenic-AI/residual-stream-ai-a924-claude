\begin{thebibliography}{11}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Arditi et~al.(2024)Arditi, Obeso, Syed, Paleka, Panickssery, Guo, and
  R{\"o}ttger]{arditi2024refusal}
Andy Arditi, Oscar Obeso, Aaquib Syed, Daniel Paleka, Nina Panickssery, Wes
  Guo, and Paul R{\"o}ttger.
\newblock Refusal in language models is mediated by a single direction.
\newblock In \emph{Advances in Neural Information Processing Systems
  (NeurIPS)}, 2024.

\bibitem[Cunningham et~al.(2023)Cunningham, Ewart, Riggs, Huben, and
  Sharkey]{cunningham2023sparse}
Hoagy Cunningham, Aidan Ewart, Logan Riggs, Robert Huben, and Lee Sharkey.
\newblock Sparse autoencoders find highly interpretable features in language
  models.
\newblock \emph{arXiv preprint arXiv:2309.08600}, 2023.

\bibitem[{Hello-SimpleAI}(2023)]{hc3dataset}
{Hello-SimpleAI}.
\newblock {HC3}: Human {ChatGPT} comparison corpus.
\newblock \url{https://huggingface.co/datasets/Hello-SimpleAI/HC3}, 2023.
\newblock CC-BY-SA-4.0 License.

\bibitem[Konen et~al.(2024)Konen, Dietz, Quality, Bauckhage, and
  Sifa]{konen2024style}
Kai Konen, Sophie Dietz, Example Quality, Christian Bauckhage, and Rafet Sifa.
\newblock Style vectors for steering generative large language models.
\newblock \emph{arXiv preprint arXiv:2402.01618}, 2024.

\bibitem[Lai et~al.(2024)Lai, Hangya, and Fraser]{lai2024style}
Wen Lai, Viktor Hangya, and Alexander Fraser.
\newblock Style-specific neurons for steering {LLMs} in text style transfer.
\newblock \emph{arXiv preprint arXiv:2410.00593}, 2024.

\bibitem[Marks and Tegmark(2024)]{marks2024geometry}
Samuel Marks and Max Tegmark.
\newblock The geometry of truth: Emergent linear structure in large language
  model representations of true/false datasets.
\newblock In \emph{Conference on Language Modeling (COLM)}, 2024.

\bibitem[Panickssery et~al.(2024)Panickssery, Gabrieli, Schulz, Tong, Hubinger,
  and Turner]{panickssery2024steering}
Nina Panickssery, Nick Gabrieli, Julian Schulz, Meg Tong, Evan Hubinger, and
  Alexander~Matt Turner.
\newblock Steering {L}lama 2 via contrastive activation addition.
\newblock In \emph{Proceedings of the 62nd Annual Meeting of the Association
  for Computational Linguistics (ACL)}, 2024.

\bibitem[Park et~al.(2023)Park, Choe, and Veitch]{park2023linear}
Kiho Park, Yo~Joong Choe, and Victor Veitch.
\newblock The linear representation hypothesis and the geometry of large
  language models.
\newblock \emph{arXiv preprint arXiv:2311.03658}, 2023.

\bibitem[{Qwen Team}(2025)]{qwen2025qwen}
{Qwen Team}.
\newblock Qwen2.5 technical report.
\newblock \url{https://huggingface.co/Qwen/Qwen2.5-3B}, 2025.

\bibitem[Turner et~al.(2023)Turner, Thiergart, Udell, Leech, Mini, and
  Zanichelli]{turner2023activation}
Alexander~Matt Turner, Lisa Thiergart, David Udell, Gavin Leech, Ulisse Mini,
  and Monte Zanichelli.
\newblock Activation addition: Steering language models without optimization.
\newblock \emph{arXiv preprint arXiv:2308.10248}, 2023.

\bibitem[Zou et~al.(2023)Zou, Phan, Chen, Campbell, Guo, Ren, Pan, Yin,
  Mazeika, Dombrowski, et~al.]{zou2023representation}
Andy Zou, Long Phan, Sarah Chen, James Campbell, Phillip Guo, Richard Ren,
  Alexander Pan, Xuwang Yin, Mantas Mazeika, Ann-Kathrin Dombrowski, et~al.
\newblock Representation engineering: A top-down approach to {AI} transparency.
\newblock \emph{arXiv preprint arXiv:2310.01405}, 2023.

\end{thebibliography}
